{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter using GOT3 (One Query Batch at a Time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T18:39:59.024357Z",
     "start_time": "2020-03-05T18:39:56.694152Z"
    }
   },
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T18:39:59.048124Z",
     "start_time": "2020-03-05T18:39:59.027381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rober\\Desktop\\ga\\eddi_discovery\\datasets\\twitter\\timeseries\n"
     ]
    }
   ],
   "source": [
    "cd datasets/twitter/timeseries/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:31:32.303318Z",
     "start_time": "2020-03-05T19:31:32.292611Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
    "\n",
    "def text_query_to_csv(text_query, count):\n",
    "    \n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query)\\\n",
    "                                                .setMaxTweets(count)\\\n",
    "                                                .setSince('2018-01-01')\\\n",
    "                                                .setUntil('2018-01-11')\n",
    "                                                                                    \n",
    "                                                \n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Creating list of chosen tweet data\n",
    "    text_tweets = [[tweet.date, tweet.text, tweet.retweets, tweet.username] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['datetime', 'text', 'retweets', 'username'])\n",
    "\n",
    "    # Converting tweets dataframe to csv file\n",
    "    tweets_df.to_csv('{}-{}k-tweets_51.csv'.format(text_query, int(count/1000)), sep=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @MrsMeyersClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:31:32.814418Z",
     "start_time": "2020-03-05T19:31:32.806771Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query = '@MrsMeyersClean'\n",
    "count = 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @SeventhGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:31:33.150196Z",
     "start_time": "2020-03-05T19:31:33.146087Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query = '@SeventhGen'\n",
    "count = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @DrBronner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:31:33.511066Z",
     "start_time": "2020-03-05T19:31:33.503220Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query = '@DrBronner'\n",
    "count = 9_999 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:31:33.842423Z",
     "start_time": "2020-03-05T19:31:33.836825Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query = '#theresgoodinside'\n",
    "count = 9_999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #plasticfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:31:34.193997Z",
     "start_time": "2020-03-05T19:31:34.186011Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query = 'plasticfree'\n",
    "count = 4_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:32:59.911750Z",
     "start_time": "2020-03-05T19:31:34.363629Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query_to_csv(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:33:00.018587Z",
     "start_time": "2020-03-05T19:32:59.915646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drbronner_20180101\n",
      "meyers_20180101\n",
      "plasticfree_20180101\n",
      "plasticfree-4k-tweets_33.csv\n",
      "plasticfree-4k-tweets_34.csv\n",
      "plasticfree-4k-tweets_35.csv\n",
      "plasticfree-4k-tweets_36.csv\n",
      "plasticfree-4k-tweets_37.csv\n",
      "plasticfree-4k-tweets_38.csv\n",
      "plasticfree-4k-tweets_39.csv\n",
      "plasticfree-4k-tweets_40.csv\n",
      "plasticfree-4k-tweets_41.csv\n",
      "plasticfree-4k-tweets_42.csv\n",
      "plasticfree-4k-tweets_43.csv\n",
      "plasticfree-4k-tweets_44.csv\n",
      "plasticfree-4k-tweets_45.csv\n",
      "plasticfree-4k-tweets_46.csv\n",
      "plasticfree-4k-tweets_47.csv\n",
      "plasticfree-4k-tweets_49.csv\n",
      "plasticfree-4k-tweets_50.csv\n",
      "plasticfree-4k-tweets_51.csv\n",
      "plasticfree-5k-tweets_32.csv\n",
      "seventhgen_20180101\n",
      "time_master.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:33:00.100451Z",
     "start_time": "2020-03-05T19:33:00.025684Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./plasticfree-4k-tweets_52.csv', index_col=False).drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T19:33:00.158124Z",
     "start_time": "2020-03-05T19:33:00.111109Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-10 23:57:43+00:00</td>\n",
       "      <td>Wow! New technology to replace plastic! #edibl...</td>\n",
       "      <td>1</td>\n",
       "      <td>joysdottir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-10 23:54:59+00:00</td>\n",
       "      <td>@DawnButlerBrent How do you feel about going #...</td>\n",
       "      <td>0</td>\n",
       "      <td>aplastic_planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-10 23:48:13+00:00</td>\n",
       "      <td>Green block PERMS project ...leading the commu...</td>\n",
       "      <td>5</td>\n",
       "      <td>sarah_sandey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-10 23:47:37+00:00</td>\n",
       "      <td>After watching #BluePlanet2 I am so happy that...</td>\n",
       "      <td>1</td>\n",
       "      <td>KEdge23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-10 23:38:16+00:00</td>\n",
       "      <td>2042 is a long way off... Theresa May aims to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>CFLFrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>2018-01-01 00:50:22+00:00</td>\n",
       "      <td>I'm doing all of that already. Being #PlasticF...</td>\n",
       "      <td>2</td>\n",
       "      <td>BenTrovato21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>2018-01-01 00:23:37+00:00</td>\n",
       "      <td>@Tom_Traver How do you feel about going #Plast...</td>\n",
       "      <td>0</td>\n",
       "      <td>aplastic_planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>2018-01-01 00:22:36+00:00</td>\n",
       "      <td>@ruthfraser05 Check out why we want to be #Pla...</td>\n",
       "      <td>0</td>\n",
       "      <td>aplastic_planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2018-01-01 00:10:08+00:00</td>\n",
       "      <td>Happy New Year to all our customers, suppliers...</td>\n",
       "      <td>0</td>\n",
       "      <td>EarthFrFoodware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2018-01-01 00:01:01+00:00</td>\n",
       "      <td>#HappyNewYear2018 #2017 saw the #world take ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>GOJUTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1563 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       datetime  \\\n",
       "0     2018-01-10 23:57:43+00:00   \n",
       "1     2018-01-10 23:54:59+00:00   \n",
       "2     2018-01-10 23:48:13+00:00   \n",
       "3     2018-01-10 23:47:37+00:00   \n",
       "4     2018-01-10 23:38:16+00:00   \n",
       "...                         ...   \n",
       "1558  2018-01-01 00:50:22+00:00   \n",
       "1559  2018-01-01 00:23:37+00:00   \n",
       "1560  2018-01-01 00:22:36+00:00   \n",
       "1561  2018-01-01 00:10:08+00:00   \n",
       "1562  2018-01-01 00:01:01+00:00   \n",
       "\n",
       "                                                   text  retweets  \\\n",
       "0     Wow! New technology to replace plastic! #edibl...         1   \n",
       "1     @DawnButlerBrent How do you feel about going #...         0   \n",
       "2     Green block PERMS project ...leading the commu...         5   \n",
       "3     After watching #BluePlanet2 I am so happy that...         1   \n",
       "4     2042 is a long way off... Theresa May aims to ...         0   \n",
       "...                                                 ...       ...   \n",
       "1558  I'm doing all of that already. Being #PlasticF...         2   \n",
       "1559  @Tom_Traver How do you feel about going #Plast...         0   \n",
       "1560  @ruthfraser05 Check out why we want to be #Pla...         0   \n",
       "1561  Happy New Year to all our customers, suppliers...         0   \n",
       "1562  #HappyNewYear2018 #2017 saw the #world take ne...         0   \n",
       "\n",
       "             username  \n",
       "0          joysdottir  \n",
       "1     aplastic_planet  \n",
       "2        sarah_sandey  \n",
       "3             KEdge23  \n",
       "4            CFLFrank  \n",
       "...               ...  \n",
       "1558     BenTrovato21  \n",
       "1559  aplastic_planet  \n",
       "1560  aplastic_planet  \n",
       "1561  EarthFrFoodware  \n",
       "1562           GOJUTE  \n",
       "\n",
       "[1563 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
